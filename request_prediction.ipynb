{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_ID</th>\n",
       "      <th>request_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.961472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>3.274127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.785475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4.455687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5.288994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   object_ID  request_time\n",
       "0          5      2.961472\n",
       "1         25      3.274127\n",
       "2          2      3.785475\n",
       "3          2      4.455687\n",
       "4          4      5.288994"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('D:/IITM/DeepCache/syntheticDataset_O50.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "292146"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "req = data[:,0]\n",
    "\n",
    "len(req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(291146, 50)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to find the probability of occurance of Oi object is caculated as Ni/1000\n",
    "# where Ni is number of occurance of Oi in past 1k req\n",
    "\n",
    "count = np.zeros(50)\n",
    "for i in range(1000):\n",
    "    for j in range(50):\n",
    "        if req[i] == j+1:\n",
    "            count[j] += 1\n",
    "\n",
    "prob = []            \n",
    "for i in range(1000,len(req)):\n",
    "    t = int(req[i] - 1)\n",
    "    count[t] += 1\n",
    "    t = int(req[i-1000] - 1)\n",
    "    count[t] -= 1\n",
    "    prob.append(count/1000)\n",
    "\n",
    "prob = np.array(prob)\n",
    "prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 12500, 50) (20, 10, 50)\n"
     ]
    }
   ],
   "source": [
    "encoder_input_data = prob[:250000,:].reshape(20,-1,50) # total samples = 20\n",
    "batch_size = 12500\n",
    "decoder_target_data = []\n",
    "for i in range(1,21):\n",
    "    temp = []\n",
    "    for j in range(10): # to predict next 10 req for every batch\n",
    "        temp.append(prob[(batch_size*i) + j,:])\n",
    "    decoder_target_data.append(temp)    \n",
    "\n",
    "decoder_target_data = np.array(decoder_target_data).reshape(20,10,-1)\n",
    "\n",
    "print(encoder_input_data.shape,decoder_target_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 10, 50)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_data = np.zeros(decoder_target_data.shape)\n",
    "decoder_input_data[1:,:,:] = decoder_target_data[:-1,:,:]\n",
    "decoder_input_data[0,:,:] = encoder_input_data[-1,-1,:]\n",
    "decoder_input_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 128 # LSTM hidden units\n",
    "dropout = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = Input(shape=(None, 50)) \n",
    "encoder = LSTM(latent_dim, dropout=dropout, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, 50)) \n",
    "decoder_lstm = LSTM(latent_dim, dropout=dropout, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoder_dense = Dense(decoder_outputs) # 1 continuous output at each timestep\n",
    "decoder_outputs = Dense(50, activation='softmax')(decoder_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 50)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None, 50)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 128), (None, 91648       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 128),  91648       input_2[0][0]                    \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 50)     6450        lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 189,746\n",
      "Trainable params: 189,746\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/30\n",
      "20/20 [==============================] - 113s 6s/step - loss: 9.4625e-04\n",
      "Epoch 2/30\n",
      "20/20 [==============================] - 112s 6s/step - loss: 9.4552e-04\n",
      "Epoch 3/30\n",
      "20/20 [==============================] - 104s 5s/step - loss: 9.4469e-04\n",
      "Epoch 4/30\n",
      "20/20 [==============================] - 85s 4s/step - loss: 9.4379e-04\n",
      "Epoch 5/30\n",
      "20/20 [==============================] - 96s 5s/step - loss: 9.4284e-04\n",
      "Epoch 6/30\n",
      "20/20 [==============================] - 89s 4s/step - loss: 9.4185e-04\n",
      "Epoch 7/30\n",
      "20/20 [==============================] - 81s 4s/step - loss: 9.4083e-04\n",
      "Epoch 8/30\n",
      "20/20 [==============================] - 79s 4s/step - loss: 9.3977e-04\n",
      "Epoch 9/30\n",
      "20/20 [==============================] - 83s 4s/step - loss: 9.3869e-04\n",
      "Epoch 10/30\n",
      "20/20 [==============================] - 84s 4s/step - loss: 9.3757e-04\n",
      "Epoch 11/30\n",
      "20/20 [==============================] - 87s 4s/step - loss: 9.3643e-04\n",
      "Epoch 12/30\n",
      "20/20 [==============================] - 88s 4s/step - loss: 9.3525e-04\n",
      "Epoch 13/30\n",
      "20/20 [==============================] - 81s 4s/step - loss: 9.3404e-04\n",
      "Epoch 14/30\n",
      "20/20 [==============================] - 87s 4s/step - loss: 9.3280e-04\n",
      "Epoch 15/30\n",
      "20/20 [==============================] - 82s 4s/step - loss: 9.3153e-04\n",
      "Epoch 16/30\n",
      "20/20 [==============================] - 88s 4s/step - loss: 9.3021e-04\n",
      "Epoch 17/30\n",
      "20/20 [==============================] - 88s 4s/step - loss: 9.2886e-04\n",
      "Epoch 18/30\n",
      "20/20 [==============================] - 87s 4s/step - loss: 9.2746e-04\n",
      "Epoch 19/30\n",
      "20/20 [==============================] - 86s 4s/step - loss: 9.2601e-04\n",
      "Epoch 20/30\n",
      "20/20 [==============================] - 92s 5s/step - loss: 9.2451e-04\n",
      "Epoch 21/30\n",
      "20/20 [==============================] - 90s 4s/step - loss: 9.2294e-04\n",
      "Epoch 22/30\n",
      "20/20 [==============================] - 72s 4s/step - loss: 9.2131e-04\n",
      "Epoch 23/30\n",
      "20/20 [==============================] - 71s 4s/step - loss: 9.1961e-04\n",
      "Epoch 24/30\n",
      "20/20 [==============================] - 74s 4s/step - loss: 9.1782e-04\n",
      "Epoch 25/30\n",
      "20/20 [==============================] - 75s 4s/step - loss: 9.1594e-04\n",
      "Epoch 26/30\n",
      "20/20 [==============================] - 75s 4s/step - loss: 9.1396e-04\n",
      "Epoch 27/30\n",
      "20/20 [==============================] - 73s 4s/step - loss: 9.1186e-04\n",
      "Epoch 28/30\n",
      "20/20 [==============================] - 77s 4s/step - loss: 9.0962e-04\n",
      "Epoch 29/30\n",
      "20/20 [==============================] - 74s 4s/step - loss: 9.0723e-04\n",
      "Epoch 30/30\n",
      "20/20 [==============================] - 73s 4s/step - loss: 9.0467e-04\n"
     ]
    }
   ],
   "source": [
    "lossNames = [\"loss\",]\n",
    "\n",
    "\n",
    "model.compile(Adam(), loss='mean_squared_error')\n",
    "history = model.fit([encoder_input_data, decoder_input_data], decoder_target_data,batch_size=batch_size,epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing The Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "pred_steps = 10\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_outputs = Dense(50, activation='softmax')(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs,\n",
    "                      [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    \n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, 50))\n",
    "    \n",
    "    # Populate the first target sequence with end of encoding series pageviews\n",
    "    target_seq[0, 0, :] = input_seq[0, -1, :]\n",
    "\n",
    "    # Sampling loop for a batch of sequences - we will fill decoded_seq with predictions\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "\n",
    "    decoded_seq = np.zeros((1,pred_steps,50))\n",
    "    for i in range(pred_steps):\n",
    "        \n",
    "        output, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        \n",
    "        decoded_seq[0,i,:] = output[0,0,:]\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, 50))\n",
    "        target_seq[0, 0, :] = output[0,0,:]\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = prob[250000:275000].reshape(1,25000,50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10, 50)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = decode_sequence(sample)\n",
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
